{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visual_genome'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c54b69996808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mvisual_genome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mVG_DATA_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./data/visual-genome'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# load vg image info and region description\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visual_genome'"
     ]
    }
   ],
   "source": [
    "import visual_genome.local as vg\n",
    "\n",
    "VG_DATA_PATH = './data/visual-genome'\n",
    "\n",
    "# load vg image info and region description\n",
    "all_image_data = vg.get_all_image_data(data_dir=VG_DATA_PATH)\n",
    "all_region_descriptions = vg.get_all_region_descriptions(data_dir=VG_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_image_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9378ffdbb845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vg data size {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-----------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[all_image_data] type {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'example'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_image_data' is not defined"
     ]
    }
   ],
   "source": [
    "print('vg data size {}'.format(len(all_image_data)))\n",
    "print('-----------------')\n",
    "print('[all_image_data] type {}'.format(type(all_image_data[0])))\n",
    "print('example')\n",
    "print(all_image_data[0])\n",
    "print('-----------------')\n",
    "print('[all_region_descriptions] list of type {}'.format(type(all_region_descriptions[0][0])))\n",
    "print('example')\n",
    "print(all_region_descriptions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualizing ground truth regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def vg_url_to_file_path(vg_data_path, url):\n",
    "    \n",
    "    res = re.search('(VG.*)/(.*.jpg)$', url)\n",
    "    return os.path.join(vg_data_path, res.group(1), res.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VG_DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-820eec8f9d60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvg_url_to_file_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVG_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_image_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'VG_DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "vg_url_to_file_path(VG_DATA_PATH, all_image_data[2].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VG_DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-30141af8365e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mimg_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIMG_NAME\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mimage_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvg_url_to_file_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVG_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_image_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mregions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_region_descriptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VG_DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "# Ref: https://github.com/ranjaykrishna/visual_genome_python_driver/blob/master/region_visualization_demo.ipynb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def visualize_regions(image_file_path, regions):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    img = Image.open(image_file_path)\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    for region in regions:\n",
    "        ax.add_patch(Rectangle((region.x, region.y),\n",
    "                               region.width,\n",
    "                               region.height,\n",
    "                               fill=False,\n",
    "                               edgecolor='red',\n",
    "                               linewidth=3))\n",
    "        ax.text(region.x, region.y, region.phrase, style='italic', bbox={'facecolor':'white', 'alpha':0.7, 'pad':10})\n",
    "    fig = plt.gcf()\n",
    "    plt.tick_params(labelbottom='off', labelleft='off')\n",
    "    plt.show()\n",
    "\n",
    "IMG_NAME = 51\n",
    "img_idx = IMG_NAME - 1\n",
    "\n",
    "image_file_path = vg_url_to_file_path(VG_DATA_PATH, all_image_data[img_idx].url)\n",
    "regions = all_region_descriptions[img_idx]\n",
    "\n",
    "visualize_regions(image_file_path, regions[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualizing regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! python describe.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: checkpoint ./model_params/train_all_val_all_bz_2_epoch_10_inject_init.pth.tar loaded\r\n",
      "[INFO]: correspond performance on val set:\r\n",
      "        map: 0.094\r\n",
      "        detmap: 0.253\r\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:01<00:00,  3.11it/s]\r\n",
      "[Result] ==== ./image_to_describe/2356897.jpg =====\r\n",
      "        SCORE 0.99  BOX [66.73, 32.55, 382.13, 342.0]\r\n",
      "        CAP giraffe in the zoo\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [24.26, 273.32, 449.35, 362.43]\r\n",
      "        CAP a fence in the background\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [255.92, 202.11, 325.96, 287.56]\r\n",
      "        CAP giraffe is brown and white\r\n",
      "\r\n",
      "        SCORE 0.94  BOX [424.32, 0.0, 453.26, 366.06]\r\n",
      "        CAP a pole in the photo\r\n",
      "\r\n",
      "[Result] ==== ./image_to_describe/2396478.jpg =====\r\n",
      "        SCORE 0.99  BOX [144.19, 16.49, 500.0, 302.23]\r\n",
      "        CAP the zebra is black and white\r\n",
      "\r\n",
      "        SCORE 0.96  BOX [152.91, 118.7, 298.71, 212.48]\r\n",
      "        CAP the head of a zebra\r\n",
      "\r\n",
      "[Result] ==== ./image_to_describe/2401512.jpg =====\r\n",
      "        SCORE 0.99  BOX [60.89, 173.13, 469.0, 364.25]\r\n",
      "        CAP a bicycle leaning against a wall\r\n",
      "\r\n",
      "        SCORE 0.98  BOX [246.31, 120.38, 328.0, 256.13]\r\n",
      "        CAP a man wearing a white shirt\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [121.65, 103.01, 254.02, 156.79]\r\n",
      "        CAP blue and white umbrella\r\n",
      "\r\n",
      "        SCORE 0.95  BOX [47.17, 145.62, 79.93, 229.59]\r\n",
      "        CAP a door on the building\r\n",
      "\r\n",
      "        SCORE 0.93  BOX [65.45, 172.83, 220.06, 311.48]\r\n",
      "        CAP a man riding a bicycle\r\n",
      "\r\n",
      "        SCORE 0.93  BOX [90.3, 298.8, 240.78, 369.82]\r\n",
      "        CAP a green and white platter\r\n",
      "\r\n",
      "        SCORE 0.91  BOX [109.24, 97.21, 260.84, 234.17]\r\n",
      "        CAP a blue and white umbrella\r\n",
      "\r\n",
      "[Result] ==== ./image_to_describe/2364956.jpg =====\r\n",
      "        SCORE 1.0  BOX [90.82, 33.64, 288.74, 455.15]\r\n",
      "        CAP a woman wearing a red shirt\r\n",
      "\r\n",
      "        SCORE 0.99  BOX [134.68, 104.87, 244.66, 248.42]\r\n",
      "        CAP a woman wearing a pink shirt\r\n",
      "\r\n",
      "        SCORE 0.96  BOX [6.0, 211.74, 62.8, 263.54]\r\n",
      "        CAP a group of flowers\r\n",
      "\r\n",
      "        SCORE 0.95  BOX [150.74, 33.2, 236.57, 128.12]\r\n",
      "        CAP the girl has long brown hair\r\n",
      "\r\n",
      "        SCORE 0.92  BOX [22.9, 152.91, 360.81, 491.29]\r\n",
      "        CAP a green grassy field\r\n",
      "\r\n",
      "        SCORE 0.91  BOX [129.92, 257.36, 156.65, 336.03]\r\n",
      "        CAP blue and white frisbee\r\n",
      "\r\n",
      "        SCORE 0.91  BOX [156.94, 229.36, 246.62, 282.0]\r\n",
      "        CAP the shorts are white\r\n",
      "\r\n",
      "[Result] ==== ./image_to_describe/2357356.jpg =====\r\n",
      "        SCORE 1.0  BOX [35.19, 39.85, 401.15, 308.83]\r\n",
      "        CAP a red double decker bus\r\n",
      "\r\n",
      "        SCORE 0.94  BOX [356.22, 191.8, 406.27, 280.52]\r\n",
      "        CAP a door on a bus\r\n",
      "\r\n",
      "[Result] ==== ./image_to_describe/IMG_3552.JPG =====\r\n",
      "        SCORE 1.0  BOX [1249.43, 1283.53, 2498.78, 2984.19]\r\n",
      "        CAP man wearing black shirt\r\n",
      "\r\n",
      "        SCORE 0.98  BOX [1396.82, 1007.22, 1900.29, 1669.35]\r\n",
      "        CAP a sign on the wall\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [733.47, 241.06, 1324.38, 1847.68]\r\n",
      "        CAP a sign on a pole\r\n",
      "\r\n",
      "        SCORE 0.96  BOX [2251.11, 1182.39, 4028.23, 1823.17]\r\n",
      "        CAP people walking on the sidewalk\r\n",
      "\r\n",
      "        SCORE 0.94  BOX [1714.71, 1220.99, 2104.35, 1682.06]\r\n",
      "        CAP a man wearing a white hat\r\n",
      "\r\n",
      "        SCORE 0.91  BOX [0.0, 432.22, 480.15, 977.8]\r\n",
      "        CAP a sign on the building\r\n",
      "\r\n",
      "[Result] ==== ./image_to_describe/51.jpg =====\r\n",
      "        SCORE 1.0  BOX [454.04, 204.11, 624.87, 427.4]\r\n",
      "        CAP man wearing a black shirt\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [264.41, 243.8, 642.42, 424.3]\r\n",
      "        CAP two people on a boat\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [28.31, 234.85, 732.02, 483.27]\r\n",
      "        CAP a man on a surfboard\r\n",
      "\r\n",
      "        SCORE 0.95  BOX [288.04, 267.33, 437.88, 408.97]\r\n",
      "        CAP two people on a surfboard\r\n",
      "\r\n",
      "        SCORE 0.95  BOX [280.6, 273.92, 358.05, 408.84]\r\n",
      "        CAP a man in a wetsuit\r\n",
      "\r\n",
      "        SCORE 0.95  BOX [132.83, 418.01, 693.17, 530.17]\r\n",
      "        CAP reflection of the man in the water\r\n",
      "\r\n",
      "        SCORE 0.95  BOX [26.37, 266.95, 300.42, 402.6]\r\n",
      "        CAP a white surfboard\r\n",
      "\r\n",
      "        SCORE 0.93  BOX [480.74, 256.93, 607.82, 398.35]\r\n",
      "        CAP the man is wearing a black shirt\r\n",
      "\r\n",
      "        SCORE 0.92  BOX [499.13, 209.34, 554.66, 253.76]\r\n",
      "        CAP a white hat on a mans head\r\n",
      "\r\n",
      "        SCORE 0.91  BOX [0.76, 0.0, 792.01, 396.56]\r\n",
      "        CAP the water is blue\r\n",
      "\r\n",
      "        SCORE 0.91  BOX [287.66, 311.93, 352.6, 389.41]\r\n",
      "        CAP the man is wearing a black shirt\r\n",
      "\r\n",
      "[Result] ==== ./image_to_describe/59.jpg =====\r\n",
      "        SCORE 0.99  BOX [124.98, 317.61, 272.71, 449.47]\r\n",
      "        CAP a white car on the road\r\n",
      "\r\n",
      "        SCORE 0.99  BOX [362.65, 299.5, 683.23, 515.97]\r\n",
      "        CAP a white car on the road\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [733.52, 255.46, 797.53, 477.72]\r\n",
      "        CAP man wearing blue shirt\r\n",
      "\r\n",
      "        SCORE 0.97  BOX [677.08, 68.9, 751.97, 149.56]\r\n",
      "        CAP a red and white sign\r\n",
      "\r\n",
      "        SCORE 0.95  BOX [356.53, 117.29, 431.66, 206.74]\r\n",
      "        CAP a red and white sign\r\n",
      "\r\n",
      "        SCORE 0.94  BOX [431.43, 152.55, 599.48, 228.19]\r\n",
      "        CAP a red and white sign\r\n",
      "\r\n",
      "[INFO] result save to ./result.json\r\n"
     ]
    }
   ],
   "source": [
    "# 使用脚本\n",
    "! python describe.py --config_json './model_params/train_all_val_all_bz_2_epoch_10_inject_init/config.json' \\\n",
    "  --model_checkpoint './model_params/train_all_val_all_bz_2_epoch_10_inject_init.pth.tar' \\\n",
    "  --img_path './image_to_describe' \\\n",
    "  --result_dir '.' \\\n",
    "  --batch_size 2 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./image_to_describe/2356897.jpg\n",
      "./image_to_describe/2396478.jpg\n",
      "./image_to_describe/2401512.jpg\n",
      "./image_to_describe/2364956.jpg\n",
      "./image_to_describe/2357356.jpg\n",
      "./image_to_describe/IMG_3552.JPG\n",
      "./image_to_describe/51.jpg\n",
      "./image_to_describe/59.jpg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "RESULT_JSON_PATH = './result.json'\n",
    "with open(RESULT_JSON_PATH, 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "for file_path in results.keys():\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def visualize_result(image_file_path, result):\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    assert isinstance(result, list)\n",
    "\n",
    "    img = Image.open(image_file_path)\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    for r in result:\n",
    "        ax.add_patch(Rectangle((r['box'][0], r['box'][1]),\n",
    "                               r['box'][2]-r['box'][0],\n",
    "                               r['box'][3]-r['box'][1],\n",
    "                               fill=False,\n",
    "                               edgecolor='red',\n",
    "                               linewidth=3))\n",
    "        ax.text(r['box'][0], r['box'][1], r['cap'], style='italic', bbox={'facecolor':'white', 'alpha':0.7, 'pad':10})\n",
    "    fig = plt.gcf()\n",
    "    plt.tick_params(labelbottom='off', labelleft='off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0fbb15a3e32f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mTO_K\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mIMG_FILE_PATH\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mvisualize_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMG_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mIMG_FILE_PATH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTO_K\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "IMG_FILE_PATH = './image_to_describe/59.jpg'\n",
    "TO_K = 10\n",
    "\n",
    "assert IMG_FILE_PATH in results.keys()\n",
    "\n",
    "visualize_result(IMG_FILE_PATH, results[IMG_FILE_PATH][:TO_K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
